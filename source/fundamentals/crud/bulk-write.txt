.. uses bulk.rst

.. _pymongo-bulk-write:

=====================
Bulk Write Operations
=====================

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

.. facet::
   :name: genre
   :values: reference

.. meta::
   :keywords: insert, update, replace, code example

This guide explains how to take advantage of {+driver-short+}'s bulk
write operation features. Executing write operations in batches
reduces the number of network round trips, increasing write
throughput.

Bulk Insert
-----------

.. versionadded:: 2.6

You can insert a batch of documents by passing a list to the
the ``~pymongo.collection.Collection.insert_many`` method. {+driver-short+}
supports large bulk insert operations by splitting the batch into smaller
sub-batches based on the maximum message size accepted by MongoDB.

The following example bulk inserts 10000 documents into a collection:

.. code-block:: python

   >>> import pymongo
   >>> db = pymongo.MongoClient().bulk_example
   >>> db.test.insert_many([{"i": i} for i in range(10000)]).inserted_ids
   [...]
   >>> db.test.count_documents({})
   10000

Mixed Bulk Write Operations
---------------------------

.. versionadded:: 2.7

{+driver-short+} supports executing mixed bulk write operations. You can run
a batch of insert, update, and remove operations together by using the bulk
write operations API.

.. _ordered_bulk:

Ordered Bulk Write Operations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

{+driver-short+} batches and sends ordered bulk write operations to the server in the
order provided for serial execution. The return value is an instance of
``~pymongo.results.BulkWriteResult``, which describes the type and count
of operations performed.

.. code-block:: python

   >>> from pprint import pprint
   >>> from pymongo import InsertOne, DeleteMany, ReplaceOne, UpdateOne
   >>> result = db.test.bulk_write(
   ...     [
   ...         DeleteMany({}),  # Remove all documents from the previous example.
   ...         InsertOne({"_id": 1}),
   ...         InsertOne({"_id": 2}),
   ...         InsertOne({"_id": 3}),
   ...         UpdateOne({"_id": 1}, {"$set": {"foo": "bar"}}),
   ...         UpdateOne({"_id": 4}, {"$inc": {"j": 1}}, upsert=True),
   ...         ReplaceOne({"j": 1}, {"j": 2}),
   ...     ]
   ... )
   >>> pprint(result.bulk_api_result)
   {'nInserted': 3,
    'nMatched': 2,
    'nModified': 2,
    'nRemoved': 10000,
    'nUpserted': 1,
    'upserted': [{'_id': 4, 'index': 5}],
    'writeConcernErrors': [],
    'writeErrors': []}

The first write failure that occurs, such as a duplicate key error, aborts the
remaining operations and raises a ``~pymongo.errors.BulkWriteError``. The ``details`` attribute of
the exception instance provides the execution results up until the failure
occurred, and details about the failure, including the operation that caused
the failure.

The following example shows a bulk write operation that raises a duplicate key error:

.. code-block:: python

   >>> from pymongo import InsertOne, DeleteOne, ReplaceOne
   >>> from pymongo.errors import BulkWriteError
   >>> requests = [
   ...     ReplaceOne({"j": 2}, {"i": 5}),
   ...     InsertOne({"_id": 4}),  # Violates the unique key constraint on _id.
   ...     DeleteOne({"i": 5}),
   ... ]
   >>> try:
   ...     db.test.bulk_write(requests)
   ... except BulkWriteError as bwe:
   ...     pprint(bwe.details)
   ...
   {'nInserted': 0,
    'nMatched': 1,
    'nModified': 1,
    'nRemoved': 0,
    'nUpserted': 0,
    'upserted': [],
    'writeConcernErrors': [],
    'writeErrors': [{'code': 11000,
                     'errmsg': '...E11000...duplicate key error...',
                     'index': 1,...
                     'op': {'_id': 4}}]}

.. _unordered_bulk:

Unordered Bulk Write Operations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

{+driver-short+} batches and sends unordered bulk write operations to the server in
arbitrary order, which means they might run in parallel. The driver reports
any errors that occur after attempting all operations.

In the following example, the first and third operations raise an error because of the unique
constraint on ``_id``. Because the operation is unordered, only the second
and fourth operations succeed.

.. code-block:: python

   >>> requests = [
   ...     InsertOne({"_id": 1}),
   ...     DeleteOne({"_id": 2}),
   ...     InsertOne({"_id": 3}),
   ...     ReplaceOne({"_id": 4}, {"i": 1}),
   ... ]
   >>> try:
   ...     db.test.bulk_write(requests, ordered=False)
   ... except BulkWriteError as bwe:
   ...     pprint(bwe.details)
   ...
   {'nInserted': 0,
    'nMatched': 1,
    'nModified': 1,
    'nRemoved': 1,
    'nUpserted': 0,
    'upserted': [],
    'writeConcernErrors': [],
    'writeErrors': [{'code': 11000,
                     'errmsg': '...E11000...duplicate key error...',
                     'index': 0,...
                     'op': {'_id': 1}},
                    {'code': 11000,
                     'errmsg': '...',
                     'index': 2,...
                     'op': {'_id': 3}}]}

Write Concern
-------------

When {+driver-short+} runs a bulk operation, it uses the``write_concern`` of the
collection in which the operation is running. The
driver reports all write concern errors, such as ``wtimeout``,
after attempting all of the operations, regardless of execution order.

.. code-block:: python
  
   >>> from pymongo import WriteConcern
   >>> coll = db.get_collection(
   ...     'test', write_concern=WriteConcern(w=3, wtimeout=1))
   >>> try:
   ...     coll.bulk_write([InsertOne({'a': i}) for i in range(4)])
   ... except BulkWriteError as bwe:
   ...     pprint(bwe.details)
   ...
   {'nInserted': 4,
    'nMatched': 0,
    'nModified': 0,
    'nRemoved': 0,
    'nUpserted': 0,
    'upserted': [],
    'writeConcernErrors': [{'code': 64...
                            'errInfo': {'wtimeout': True},
                            'errmsg': 'waiting for replication timed out'}],
    'writeErrors': []}
